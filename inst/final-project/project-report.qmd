---
title: "Introducing `irwpkg` for the Item Response Warehouse (IRW)"
date: December 5, 2024
author: "Hansol Lee & Michael Hardy"
format: 
  revealjs:
    slideNumber: true
---

```{r}
#| echo: false
library(psych)
library(tidyverse)
library(irwpkg)
library(mirt)
library(purrr)
library(dplyr)
library(mokken)
library(ggplot2)
library(lavaan)
```

# Problem: Usability Challenges of IRW

The [Item Response Warehouse (IRW)](https://datapages.github.io/irw/) is a large-scale database of harmonized item response datasets hosted [here](https://redivis.com/datasets/as2e-cv7jb41fd).

However, its usability has been limited by the lack of a dedicated programming interface, making data access and analysis inefficient.

# Introducing `irwpkg`

`irwpkg` provides a simple, efficient interface for accessing and analyzing IRW datasets, providing tools for:

1.  **Exploration**: Browse and identify datasets.

2.  **Retrieval**: Fetch datasets into R.

3.  **Reformatting**: Prepare data for psychometric analysis.

# 1. Exploration

Gain insights into the IRW database and find datasets relevant to your analysis using tools for listing, summarizing, and filtering.

-   `list_available_datasets()`

-   `get_database_metadata()` & `get_table_metadata()`

-   `show_overall_statistics()` & `visualize_metadata_distributions()`

-   

    ## `filter_tables()`

## List Available Datasets

Use `list_available_datasets()` to view all datasets and their metadata (names, row counts, variable counts).

```{r}
#| echo: true
datasets <- list_available_datasets()
dim(datasets)
head(datasets)

```

## Database Metadata

Retrieve high-level metadata for the entire database using `get_database_metadata()`:

```{r}
#| echo: true
db_info <- get_database_metadata()
```

## Database Metadata (cont.)

You can also get metadata about individual datasets using `get_table_metadata()`:

```{r}
#| echo: true
table_info <- get_table_metadata("lessR_Mach4")
```

## Overall Statistics

View statistical summaries for key dataset attributes with `show_overall_statistics()`:

```{r}
#| echo: true
show_overall_statistics()
```

## Overall Statistics (cont.)

Use `visualize_metadata_distributions()` to generate histograms of dataset attributes.

```{r}
#| echo: true
visualize_metadata_distributions()
```

## Overall Statistics (cont.)

Specify custom ranges for attributes if needed:

```{r}
#| echo: true
visualize_metadata_distributions(ranges = list(
  id_count = c(0, 10000),
  resp_count = c(0, 100000),
  item_count = c(0, 150),
  sparsity = c(0, 2)
))
```

## Filter Datasets by Criteria

Retrieve datasets that match specific numeric ranges of key attributes:

```{r}
#| echo: true
matching_tables <- filter_tables(
  id_count = c(100, 1000), 
  sparsity = c(0.1, 0.5))
print(matching_tables)
```

## Filter Datasets by Criteria (cont.)

Filter datasets that include specific columns (`date`, `rt`, or `rater`):

```{r}
#| echo: true
matching_tables <- filter_tables(has_rater = TRUE)

print(matching_tables)
```

## Filter Datasets by Criteria (cont.)

You can combine multiple criteria to refine your search:

```{r}
#| echo: true
matching_tables <- filter_tables(
  id_count = c(100, 10000), 
  has_rater = TRUE
)
print(matching_tables)
```

# 2. Retrieval

Once youâ€™ve identified the desired datasets, fetch them into R for analysis.

-   `fetch_data()`
-   `download_data()`

## Fetch a single dataset

Use `fetch_data()` to retrieve a single dataset:

```{r}
#| echo: true
swmd_mokken <- fetch_data(name = "swmd_mokken")
str(swmd_mokken)

```

## Fetch multiple datasets

Retrieve multiple datasets by providing their names:

```{r}
#| echo: true
datasets <- fetch_data(c("fractals_rating", "spelling2pronounce_edwards2023"))
print(names(datasets))
str(datasets$fractals_rating)

```

## Fetch multiple datasets (cont.)

Alternatively, you can use the output of `filter_tables()` directly:

```{r}
#| echo: true
matching_tables <- filter_tables(has_rater = TRUE)
datasets <- fetch_data(matching_tables)
print(names(datasets))
```

## Download datasets

Save datasets locally with `download_data()`:

```{r}
#| echo: true
#| eval: false
download_data("swmd_mokken", path = "mydata.csv", overwrite=TRUE)
```

# 3. Reformatting

Reformat IRW data for analysis with popular psychometric tools.

-   `irw_rename()`
-   `reformat()`

## Rename IRW Variables

Use `irw_rename()` to rename IRW variables for consistency. Similar to but less flexible than `janitor::clean_names()`, it can handle character vectors or any object with names and standardize them.

```{r}
#| echo: true
#| eval: false
test_vec <- c("InTeREsTiNG.VAR", "another.VAR", "this.$&^!_VAR")
irw_rename(test_vec)
```

## Example item information analysis workflow

Fetch a dataset, reformat it, and analyze item information functions using `mirt`:

```{r}
#| echo: true
df <- fetch_data(name = "lessR_Mach4")
rdf = reformat(df)
mirtmod = mirt::mirt(rdf)
plot(mirtmod, type="infotrace")
```

## Example nonparametric IRT item workflow

Fetch a dataset, reformat it, and analyze to check for item monotonicity using `mokken`:

```{r}
#| echo: true
df <- fetch_data(name = "NAMPRB_Siwiak_2024_AOT")
rdf = reformat(df, package = "mokken")
mokmod = mokken::check.monotonicity(rdf)
plot(mokmod, ask=FALSE,items =c(1))
```

## Example omega reliability analysis workflow based item response times

Fetch a dataset, reformat it, and analyze it with `psych` function `omega` for factor analysis:

```{r}
#| echo: true
df <- fetch_data(name = "dd_rotation")
rdf = reformat(df, package = "psych", resp = "rt")
famod = psych::omega(rdf)
plot(famod)
summary(famod)
```

## Example exploratory factor analysis on longitudinal data

Fetch a dataset, reformat it, and analyze it with `lavaan` function `efa` for factor analysis:

```{r}
#| echo: true
df <- fetch_data(name = "COACH_Chen_2022_ADL")
rdf = reformat(df,package = "lavaan",item=c("item","wave"))
lavmod = lavaan::efa(rdf)
summary(lavmod)
```

# The End
